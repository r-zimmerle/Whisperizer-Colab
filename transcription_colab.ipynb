{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2142,
     "status": "ok",
     "timestamp": 1740960109772,
     "user": {
      "displayName": "NEXUS - DCG",
      "userId": "08238528941623053962"
     },
     "user_tz": 180
    },
    "id": "R1LgceSIRlB5",
    "outputId": "986a9e7c-d2f9-456b-fd2e-3a3f6c4a4af2"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1740960113640,
     "user": {
      "displayName": "NEXUS - DCG",
      "userId": "08238528941623053962"
     },
     "user_tz": 180
    },
    "id": "3_g2EL-oSdOr",
    "outputId": "613dd686-73ca-42c6-95fd-903bdd98e301"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define input folder (videos) and check available files\n",
    "audio_folder = \"/content/drive/My Drive/videos\"\n",
    "files = os.listdir(audio_folder)\n",
    "\n",
    "print(\"Found files:\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1740960116721,
     "user": {
      "displayName": "NEXUS - DCG",
      "userId": "08238528941623053962"
     },
     "user_tz": 180
    },
    "id": "yFLcR332Sfxy",
    "outputId": "ccac9032-365b-4b63-ba06-d36869b3bd3e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = \"/content/drive/My Drive/videos\"\n",
    "output_folder = \"/content/drive/My Drive/audios\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Convert video files to audio\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.lower().endswith((\".mp4\", \".mov\", \".avi\")):  # Supports multiple video formats\n",
    "        input_path = os.path.join(input_folder, file)\n",
    "        output_path = os.path.join(output_folder, os.path.splitext(file)[0] + \".m4a\")\n",
    "\n",
    "        cmd = [\"ffmpeg\", \"-i\", input_path, \"-vn\", \"-acodec\", \"aac\", \"-b:a\", \"192k\", output_path, \"-y\"]\n",
    "        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "print(\"✅ Conversion completed! Audio files saved in:\", output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740960119222,
     "user": {
      "displayName": "NEXUS - DCG",
      "userId": "08238528941623053962"
     },
     "user_tz": 180
    },
    "id": "6GA1x9_7Sune",
    "outputId": "d0cdb00b-0adb-41a4-d754-af17c8a5e351"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "gpu_available = torch.cuda.is_available()\n",
    "gpu_name = torch.cuda.get_device_name(0) if gpu_available else \"No GPU detected\"\n",
    "\n",
    "print(f\"GPU available: {gpu_available}\")\n",
    "print(f\"GPU Name: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9033,
     "status": "ok",
     "timestamp": 1740960132393,
     "user": {
      "displayName": "NEXUS - DCG",
      "userId": "08238528941623053962"
     },
     "user_tz": 180
    },
    "id": "q0VcBMvSSzwj",
    "outputId": "90546686-800e-4ad7-fbf4-f247f22c4de8"
   },
   "outputs": [],
   "source": [
    "# Install Whisper and FFmpeg\n",
    "!pip install -q git+https://github.com/openai/whisper.git\n",
    "!sudo apt update && sudo apt install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18088,
     "status": "ok",
     "timestamp": 1740960165290,
     "user": {
      "displayName": "NEXUS - DCG",
      "userId": "08238528941623053962"
     },
     "user_tz": 180
    },
    "id": "OP23zCgeTUp3",
    "outputId": "3e28035f-700a-486a-952a-2bab8db3a6cd"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "print(\"Loading Whisper model...\")\n",
    "model = whisper.load_model(\"turbo\", device=\"cuda\")  # Using the 'turbo' model for better performance\n",
    "print(\"✅ Whisper 'turbo' model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18815,
     "status": "ok",
     "timestamp": 1740960187874,
     "user": {
      "displayName": "NEXUS - DCG",
      "userId": "08238528941623053962"
     },
     "user_tz": 180
    },
    "id": "NHyha-FuTZL5",
    "outputId": "47086232-66a5-44be-ee80-d7914ba41053"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "\n",
    "# Define paths in Google Drive\n",
    "input_folder = \"/content/drive/My Drive/audios\"  # Folder with .m4a audio files\n",
    "output_folder = \"/content/drive/My Drive/transcripts\"  # Folder to save transcripts\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load Whisper model on GPU ('turbo' model for faster processing)\n",
    "model = whisper.load_model(\"turbo\", device=\"cuda\")  # Faster and optimized model\n",
    "\n",
    "# Process all .m4a files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".m4a\"):\n",
    "        input_path = os.path.join(input_folder, file_name)\n",
    "        output_path = os.path.join(output_folder, file_name.replace(\".m4a\", \".txt\"))\n",
    "\n",
    "        print(f\"Transcribing: {file_name} using GPU...\")\n",
    "\n",
    "        # Transcribe the audio\n",
    "        result = model.transcribe(input_path, language=\"en\")  # Default language set to English (can be changed)\n",
    "\n",
    "        # Save the transcript\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(result[\"text\"])\n",
    "\n",
    "        print(f\"Transcription saved at: {output_path}\")\n",
    "\n",
    "print(\"✅ Transcription completed! All files have been processed.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPXzbR6N5nJ8+aZYpmhk6GO",
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1Pq4tpThptKInswL_KsmeHU14xQWI4mzt",
     "timestamp": 1740960272099
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
